# -*- coding: utf-8 -*-
import tensorflow as tf
import random
import numpy as np
from data_preprocessing import word_split,word_lemmatizer,stopwords_filter,words2vec,words2vec_label  #导入自定义数据预处理函数
from tf_idf import feature_select  #导入tf-idf词频选择函数
import time
import info_gain
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
from sklearn import metrics
"""
函数说明：深度神经网络模型(900-3000-3000-1000-23)
Parameters:
    data_vec:数据集列表
    label_vec:标签列表
Returns: 
"""
def dnn_model(data_vec,label_vec):

    # 载入数据集并划分数据集为训练集和测试集
    trainset=data_vec[:]
    trainlabel=label_vec[:]
    testset=data_vec[9700:]
    testlabel=label_vec[9700:]

    # 设置批次的大小
    batch_size = 100
    n_batch=97

    # 定义批量梯度下降
    def next_batch(trainset, trainlabel, size):
        # random.sample()可以从指定的序列中，随机的截取指定长度的片断，存储索引号
        batchset = random.sample(range(len(trainset)), size)
        trainset_batch = trainset[batchset[0]]
        trainlabel_batch = trainlabel[batchset[0]]
        for i in range(1, size):
            trainset_batch = np.row_stack((trainset_batch, trainset[batchset[i]]))
            trainlabel_batch = np.row_stack((trainlabel_batch, trainlabel[batchset[i]]))
        return trainset_batch, trainlabel_batch

    # 定义初始化权值函数
    def weight_variable(shape):
        initial = tf.truncated_normal(shape, stddev=0.1)
        return tf.Variable(initial)

    # 定义初始化偏置函数
    def bias_variable(shape):
        initial = tf.constant(0.1, shape=shape)
        return tf.Variable(initial)

    # 定义三个placeholder
    x = tf.placeholder(tf.float32, [None,1024])
    y = tf.placeholder(tf.float32, [None, 23])
    keep_prob = tf.placeholder(tf.float32)  # 存放百分率

    # 创建一个多层神经网络模型
    # 第一个隐藏层
    W1 = weight_variable([1024,2000])
    b1 = bias_variable([2000])
    L1 = tf.nn.tanh(tf.matmul(x, W1) + b1)
    L1_drop = tf.nn.dropout(L1, keep_prob)  # keep_prob设置工作状态神经元的百分率
    '''
    # 第二个隐藏层
    W4 = weight_variable([2000,2000])
    b4 = bias_variable([2000])
    L4 = tf.nn.tanh(tf.matmul(L1_drop, W4) + b4)
    L4_drop = tf.nn.dropout(L4, keep_prob)
    '''
    # 第二个隐藏层
    W2 = weight_variable([2000, 2000])
    b2 = bias_variable([2000])
    L2 = tf.nn.tanh(tf.matmul(L1_drop, W2) + b2)
    L2_drop = tf.nn.dropout(L2, keep_prob)

    # 第三个隐藏层
    W3 = weight_variable([2000,1000])
    b3 = bias_variable([1000])
    L3 = tf.nn.tanh(tf.matmul(L2_drop, W3) + b3)
    L3_drop = tf.nn.dropout(L3, keep_prob)
    # 输出层
    W4 = weight_variable([1000,23])
    b4 = bias_variable([23])
    prediction = tf.nn.softmax(tf.matmul(L3_drop, W4) + b4)



    # 定义交叉熵代价函数
    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=prediction))

    # 定义反向传播算法（使用梯度下降算法）
    train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)
    #train_step = tf.train.AdamOptimizer(1e-2).minimize(loss)
    # 结果存放在一个布尔型列表中(argmax函数返回一维张量中最大的值所在的位置)
    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1))




    # 求准确率(tf.cast将布尔值转换为float型)
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

    # 创建会话
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())  # 初始化变量

        # 训练次数
        for i in range(20):
            for batch in range(n_batch):
                batch_xs, batch_ys = next_batch(trainset,trainlabel,batch_size)
                sess.run(train_step, feed_dict={x: batch_xs, y: batch_ys, keep_prob: 1.0})
            # 测试数据计算出的准确率
            test_acc = sess.run(accuracy, feed_dict={x: testset, y: testlabel, keep_prob: 1.0})
            print("Iter" + str(i) + ",Testing Accuracy=" + str(test_acc))


            '''
            plt.plot(i,test_acc,'ro-') #画图
            plt.title('Accuracy change as the number of iterations increases')
            plt.xlabel('Number of iterations')
            plt.ylabel('Accuracy')
            #plt.legend()
            plt.show()
            '''

        '''
        y_p = tf.argmax(prediction, 1)
        y_pred = sess.run(y_p, feed_dict={x: testset, y: testlabel, keep_prob: 1.0})

        y_true = tf.argmax(y, 1)

        confusion_matrix(y_true, y_pred)
        print("Precision", metrics.precision_score(y_true, y_pred))
        print("Recall", metrics.recall_score(y_true, y_pred))
        print("f1_score", metrics.f1_score(y_true, y_pred))
        '''







if __name__=='__main__':

    list_word_split, category_labels=word_split('all_datasets_10000.xls') #获得每条文本的分词列表和标签列表
    print('分词成功')

    list_words_lemmatizer=word_lemmatizer(list_word_split)  #词性还原
    print('词性还原成功')

    list_filter_stopwords=stopwords_filter('stopwords.txt',list_words_lemmatizer) #获得停用词过滤后的列表
    print("停用词过滤成功")
    dict_feature_select=feature_select(list_filter_stopwords) #使用TF-IDF进行特征提取
    feaNum=len(dict_feature_select)   #求特征词字典的个数

    features_vocabSet=[]
    for i in range(2000):     #选择前1024个词作为重要特征词集
        features_vocabSet.append(dict_feature_select[i][0])
    print('根据tf-idf词集提取成功')


    #使用信息增益方法提取特征词集
    docvec_label = words2vec_label(features_vocabSet, list_word_split, category_labels)  # 数据集转换
    features_info = info_gain.chooseBestFeatureToSplit(docvec_label)  # 计算词集的信息增益
    # 获取词集
    feature_words = []
    for i in range(1024):
         feature_words.append(features_vocabSet[features_info[i][0]])
    print('根据信息增益提取特征词集成功')
    #print(feature_words)


    docvec,labelvec=words2vec(feature_words,list_word_split,category_labels)
    print('构建词向量成功')

    print('使用深度神经网络模型进行训练')
    start=time.clock()
    dnn_model(docvec,labelvec)
    end=time.clock()
    print("training time:"+str(end-start))
