# -*- coding: utf-8 -*-

from data_preprocessing import word_split,word_lemmatizer,stopwords_filter,words2vec,words2vec_label  #导入自定义数据预处理函数
from tf_idf import feature_select  #导入tf-idf词频选择函数
import time
import info_gain
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report
from sklearn import svm
from sklearn.neighbors import KNeighborsClassifier


"""
函数说明:KNN分类器
Parameters:
    data_vec - 文本向量化数据集
    label_vec - 类别标签
Returns:
    test_accuracy - 分类器精度
"""
def KNN_model(data_vec,label_vec):
    # 载入数据集并划分数据集为训练集和测试集
    trainset = data_vec[:]
    trainlabel = label_vec[:]
    testset = data_vec[9700:]
    testlabel = label_vec[9700:]

    model = KNeighborsClassifier()
    model.fit(trainset, trainlabel)
    pre=model.predict(testset)
    test_accuracy = model.score(testset, testlabel)
    test_report=classification_report(testlabel,pre)
    return test_accuracy,test_report

"""
函数说明:朴素贝叶斯分类器
Parameters:
    data_vec - 文本向量化数据集
    label_vec - 类别标签
Returns:
    test_accuracy - 分类器精度
"""
def naive_bayes_model(data_vec,label_vec):
    # 载入数据集并划分数据集为训练集和测试集
    trainset = data_vec[:]
    trainlabel = label_vec[:]
    testset = data_vec[9700:]
    testlabel = label_vec[9700:]

    model = MultinomialNB()
    model.fit(trainset, trainlabel)
    pre=model.predict(testset)
    test_accuracy = model.score(testset, testlabel)
    test_report=classification_report(testlabel,pre)
    return test_accuracy,test_report

"""
函数说明:SVM分类器
Parameters:
    data_vec - 文本向量化数据集
    label_vec - 类别标签
Returns:
    test_accuracy - 分类器精度
"""
def svm_model(data_vec,label_vec):
    # 载入数据集并划分数据集为训练集和测试集
    trainset = data_vec[:9700]
    trainlabel = label_vec[:9700]
    testset = data_vec[9700:]
    testlabel = label_vec[9700:]
    model=svm.SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape=None, degree=3,
                  gamma='auto', kernel='rbf', max_iter=-1, probability=False, random_state=None, shrinking=True,
                  tol=0.001, verbose=False)
    model.fit(trainset,trainlabel)
    pre = model.predict(testset)
    test_accuracy=model.score(testset,testlabel)
    test_report=classification_report(testlabel,pre)
    return  test_accuracy,test_report


if __name__=='__main__':

    list_word_split, category_labels=word_split('all_datasets_10000.xls') #获得每条文本的分词列表和标签列表
    print('分词成功')

    list_words_lemmatizer=word_lemmatizer(list_word_split)  #词性还原
    print('词性还原成功')

    list_filter_stopwords=stopwords_filter('stopwords.txt',list_words_lemmatizer) #获得停用词过滤后的列表
    print("停用词过滤成功")

    dict_feature_select=feature_select(list_filter_stopwords) #使用TF-IDF进行特征提取
    feaNum=len(dict_feature_select)   #求特征词字典的个数
    features_vocabSet=[]
    for i in range(1024):     #选择前1024个词作为重要特征词集
        features_vocabSet.append(dict_feature_select[i][0])
    print('根据tf-idf词集提取成功')

    '''
    #使用信息增益方法提取特征词集
    docvec_label = words2vec_label(features_vocabSet, list_word_split, category_labels)  # 数据集转换
    features_info = info_gain.chooseBestFeatureToSplit(docvec_label)  # 计算词集的信息增益
    # 获取词集
    feature_words = []
    for i in range(900):
         feature_words.append(features_vocabSet[features_info[i][0]])
    print('根据信息增益提取特征词集成功')
    '''

    docvec,labelvec=words2vec(features_vocabSet,list_word_split,category_labels)
    print('构建词向量成功')

    print('使用朴素贝叶斯模型进行训练并求出准确率')
    #test_accuracy,test_report = naive_bayes_model(docvec,category_labels)
    #test_accuracy, test_report=svm_model(docvec,category_labels)
    test_accuracy,test_report=KNN_model(docvec,category_labels)
    print(test_accuracy)
    print(test_report)

