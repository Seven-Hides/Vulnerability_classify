# -*- coding: utf-8 -*-
from vul_cnn import word_split,word_lemmatizer
from collections import defaultdict
import operator

list_word_split, category_labels=word_split('datasets_all.xlsx') #获得每条文本的分词列表和标签列表
for row in list_word_split:
    for i in range(len(row)):
        row[i]=row[i].lower()

list_words_lemmizer=word_lemmatizer(list_word_split)
# 总词频统计
doc_frequency = defaultdict(int)
for word_list in list_words_lemmizer:
    for i in word_list:
        doc_frequency[i] += 1

dict_feature_select=sorted(doc_frequency.items(),key=operator.itemgetter(1),reverse=False)
print(dict_feature_select)
print(len(dict_feature_select))

with open('stops.txt','w') as fw:
    for i in range(400):
        fw.write(dict_feature_select[i][0])
        fw.write('\t')
        fw.write(str(dict_feature_select[i][1]))
        fw.write('\n')



